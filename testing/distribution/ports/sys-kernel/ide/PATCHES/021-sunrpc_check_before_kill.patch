# This is a BitKeeper generated diff -Nru style patch.
#
# ChangeSet
#   2005/01/04 19:35:12+01:00 trond.myklebust@fys.uio.no 
#   RPC: Fix a bug in rpc_killall_tasks().
#   
#     Shirly Ma reported seeing problems with rpc_killall_tasks() causing
#     the task->tk_magic debugging test to trigger. It turns out we may be
#     killing tasks that are not yet running or even initialized.
#   
#   Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
# 
# net/sunrpc/sched.c
#   2005/01/04 01:00:00+01:00 trond.myklebust@fys.uio.no +9 -6
#   RPC: Fix a bug in rpc_killall_tasks().
# 
diff -Nru a/net/sunrpc/sched.c b/net/sunrpc/sched.c
--- a/net/sunrpc/sched.c	2005-01-04 19:45:47 -08:00
+++ b/net/sunrpc/sched.c	2005-01-04 19:45:47 -08:00
@@ -762,11 +762,6 @@
 	if (!RPC_IS_ASYNC(task))
 		init_waitqueue_head(&task->u.tk_wait.waitq);
 
-	/* Add to global list of all tasks */
-	spin_lock(&rpc_sched_lock);
-	list_add(&task->tk_task, &all_tasks);
-	spin_unlock(&rpc_sched_lock);
-
 	if (clnt) {
 		atomic_inc(&clnt->cl_users);
 		if (clnt->cl_softrtry)
@@ -779,6 +774,11 @@
 	task->tk_magic = 0xf00baa;
 	task->tk_pid = rpc_task_id++;
 #endif
+	/* Add to global list of all tasks */
+	spin_lock(&rpc_sched_lock);
+	list_add_tail(&task->tk_task, &all_tasks);
+	spin_unlock(&rpc_sched_lock);
+
 	dprintk("RPC: %4d new task procpid %d\n", task->tk_pid,
 				current->pid);
 }
@@ -952,12 +952,15 @@
 	 * Spin lock all_tasks to prevent changes...
 	 */
 	spin_lock(&rpc_sched_lock);
-	alltask_for_each(rovr, le, &all_tasks)
+	alltask_for_each(rovr, le, &all_tasks) {
+		if (! RPC_IS_ACTIVATED(rovr))
+			continue;
 		if (!clnt || rovr->tk_client == clnt) {
 			rovr->tk_flags |= RPC_TASK_KILLED;
 			rpc_exit(rovr, -EIO);
 			rpc_wake_up_task(rovr);
 		}
+	}
 	spin_unlock(&rpc_sched_lock);
 }
 
